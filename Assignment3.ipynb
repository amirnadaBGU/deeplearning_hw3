{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V88HswjzApoz"
      },
      "source": [
        "# Deep Learning and Its Applications to Signal and Image Processing and Analysis - Assignment 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J435x4PWJF0A"
      },
      "source": [
        "## Introduction\n",
        "In this assignment, you will perform an image classification task on the CIFAR-10 dataset using two\n",
        "model families: Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). The objectives\n",
        "are to develop models, apply explainability tools (Grad-CAM and attention visualization), and evaluate\n",
        "comparative performance using confusion matrices and other metrics. In this assignment, you will also\n",
        "learn how to use the pytorch-lightning library. This library simplifies model building and training, and\n",
        "it also supports automatic logging to Weights & Biases. There is a complementary notebook attached\n",
        "to the assignment. A complementary notebook is provided with this assignment. It is intended for your\n",
        "convenience, and you are free to modify it as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMV6DvqCNibL"
      },
      "source": [
        "### Imports and mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scJPk5R6GMQu"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning\n",
        "# üì¶ Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import wandb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# üßπ Set seeds and configs\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4gUQ3-MSj4g",
        "outputId": "991b983e-03ba-46e9-cc4c-1670ebc80ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR-WkNcpSqP1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XeebVJOK2u"
      },
      "source": [
        "## 1. CNN Classification and Grad-CAM Explainability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsyAmozEJN-C"
      },
      "source": [
        "In this section, you will implement a CNN from scratch and apply Grad-CAM to explain the model predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecrqustYN6kL"
      },
      "source": [
        "###  1.1. Load and Preprocess CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9vLbKvJBswB"
      },
      "source": [
        "a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KF7SJaBNnZc"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = ... #raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "#‚¨áÔ∏è Load dataset\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "def show_example_per_label(dataset):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1CCx4koBp9g"
      },
      "source": [
        "b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3TtmfZgYP1i"
      },
      "outputs": [],
      "source": [
        "# Split the database into train, validation and test data set.\n",
        "raise NotImplementedError(\"TODO: Implement this part\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Nc6iLqCt3N"
      },
      "source": [
        "c."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e4FXUTRCv86"
      },
      "outputs": [],
      "source": [
        "# Show histogram of the categorical split for train, validation and test.\n",
        "raise NotImplementedError(\"TODO: Implement this part\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cycq1A3GOGMm"
      },
      "source": [
        "###  1.2. Define CNN in PyTorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLEAg2zTDCP1"
      },
      "source": [
        "a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4JO7FXcOFmk"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(pl.LightningModule):\n",
        "    def __init__(self, lr):\n",
        "        raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        raise NotImplementedError(\"TODO: Implement this part\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdomBb5LOmHq"
      },
      "source": [
        "b. Your model should achieve an accuracy of at least 0.80 on the training set, and at least 0.70 on both the validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn0QyuIhOl3D"
      },
      "outputs": [],
      "source": [
        "# ü™Ñ Init wandb logger\n",
        "wandb_logger = WandbLogger(project=\"CNN-CIFAR10\", log_model=True)\n",
        "\n",
        "# ‚ö° Instantiate model and trainer\n",
        "model = SimpleCNN(lr=...)\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    #raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    #raise NotImplementedError(\"TODO: Implement this part\")\n",
        ")\n",
        "\n",
        "# üèãÔ∏è‚Äç‚ôÇÔ∏è Train\n",
        "trainer.fit(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJR95o9wOusC"
      },
      "source": [
        "c."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yquHXLVuPCCm"
      },
      "outputs": [],
      "source": [
        "# üîç Evaluate\n",
        "trainer.test(model, dataloaders=test_loader)\n",
        "\n",
        "#Show F1 score and confusion matrix you can do it in def on_test_epoch_end(self): and log it to wandb\n",
        "\n",
        "# üíæ Save the model in thr last epoch if saved by metric  \n",
        "torch.save(model.state_dict(), \"cnn_cifar10_checkpoint.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOVDHUoifGbs"
      },
      "source": [
        "## 1.3 Explainability with Grad-CAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FG-qhsjfPzT"
      },
      "source": [
        "a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IajQrqlhfGNs"
      },
      "outputs": [],
      "source": [
        "!pip install grad-cam --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8srEIKxwfWPb"
      },
      "outputs": [],
      "source": [
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "# Define the target layer for Grad-CAM (adjust if needed)\n",
        "target_layer = ... # raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "cam = GradCAM(model=model, target_layers=[target_layer])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_6oN4Wlfndu"
      },
      "source": [
        "generate Grad-CAM heatmaps for several test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4_NSMx4fqNV"
      },
      "outputs": [],
      "source": [
        "# generate Grad-CAM heatmaps for several test image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIBSAFLDj6Q1"
      },
      "source": [
        "## 2. Vision Transformer (ViT) and Attention Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovuaqHqj8MH"
      },
      "source": [
        "In this section, you will implement a Vision Transformer (ViT) from scratch and compare it to the CNN\n",
        "model developed in Section 1. Additionally, you will visualize attention maps to gain insight into the\n",
        "model‚Äôs decision process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aq-OFickLAa"
      },
      "source": [
        "### 2.1 Implementing the Vision Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XnBOzNKGsCB"
      },
      "source": [
        "a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGbJ7K7JkTel"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels=..., patch_size=..., emb_size=..., img_size=...):\n",
        "      raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "    def forward(self, x):\n",
        "      raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "class ViTWithAttention(nn.Module):\n",
        "  def __init__(self, img_size=..., patch_size=..., in_channels=..., num_classes=...,):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "class ViTLightningModule(pl.LightningModule):\n",
        "  def __init__(self, lr=...):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "  \n",
        "  def test_step(self, batch, batch_idx):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJTV2p6koSR"
      },
      "source": [
        "b. Your model should achieve an accuracy of at least 0.70 on the training set, and at least 0.60 on both the validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltGRzNoNkhyG"
      },
      "outputs": [],
      "source": [
        "# ü™Ñ Init wandb logger\n",
        "wandb_logger = WandbLogger(project=\"ViT-CIFAR10\", log_model=True)\n",
        "\n",
        "# ‚ö° Instantiate model and trainer\n",
        "model = ViTLightningModule(lr=...)\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    # raise NotImplementedError(\"TODO: Implement this part\")\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    # raise NotImplementedError(\"TODO: Implement this part\")\n",
        ")\n",
        "\n",
        "# üèãÔ∏è‚Äç‚ôÇÔ∏è Train\n",
        "trainer.fit(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDumUnhsHMzQ"
      },
      "source": [
        "c."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV6DezK3ruaV"
      },
      "outputs": [],
      "source": [
        "# üîç Evaluate\n",
        "trainer.test(model, dataloaders=test_loader)\n",
        "\n",
        "#Show F1 score and confusion matrix you can do it in def on_test_epoch_end(self): and log it to wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP8H4jagtJK4"
      },
      "source": [
        "### 2.2 Visualizing Attention Maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VycyoCzotpcE"
      },
      "outputs": [],
      "source": [
        "def visualize_attention(model, image_tensor, patch_size=4):\n",
        "    raise NotImplementedError(\"TODO: Implement this part\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
